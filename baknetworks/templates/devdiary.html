{% extends "base.html" %}

{% block content %}

<!-- Jumbotron -->

<div class="jumbotron jumbotron-fluid">
    <div class="container-fluid">
        <div class="d-flex justify-content-center text-center">
            <h1 class="display-1">
                {%if current_user.is_authenticated %}

                Welcome to the Dev Diary, {{current_user.name.split(" ")[0]}}

                {%else%}

                Dev Diary

                {%endif%}

             </h1>
        </div>
        
    </div>
</div>

 <!-- Dev Diary -->

<div class='container'>

<!-- Accordian Appearance -->

<div class="accordion" id="accordianDev">

  <!-- Entry One -->  

  <div class="card">   
      <div class="card-header" id="headingOne">
        <h2 class="mb-0">
          <button class="btn btn-dark btn-block text-center collapsed" type="button" data-toggle="collapse" data-target="#collapseOne" aria-expanded="false" aria-controls="collapseOne">
            Dev Diary #1 - Hello, World! 
          </button>
        </h2>
      </div>
  
      <div id="collapseOne" class="collapse" aria-labelledby="headingOne" data-parent="#accordianDev">
        <div class="card-body">
         
                    <p><strong>29/06/2020</strong></p>
         
                    <p>Having achieved a BA in Music, Multimedia, and Electrical Engineering in 2012, I was eager to pursue a career in embedded systems or software development. What felt like hundreds of job applications, and subsequent interviews, over the course of six months all came down to the all too familiar <em>“lack of experience”</em>.  I eventually took to an admin job at a Building Society, as a steppingstone and to make ends meet. 8 years later I’m self-employed, and having progressed through administration, case handling, quality assurance, I’m currently a specialist intermediary between the Building Society and the Financial Ombudsman Service. But my interest in technology, logic, problem solving, and development has never stopped thriving.</p> 

                    <p>For Christmas in 2018, my brother would only give me my Christmas present on the proviso that I could solve a mathematical logic problem.  He gave me an email address, and that the gift was on the email account. I just had to guess the password, using python, with the following hint: </p>
                    
                    <pre class="prettyprint">
    print("My password is the first prime number which contains at least 5 sevens...") 
                    </pre>

                    <p>While I’d never used python before, having had more experience in C than anything else, I was excited to be set a task that required learning the syntax of a new language, and I didn’t realise just how much this would reignite my passion for programming.</p>
                    
                    <pre class="prettyprint">
    flag = False
    primeFlag = 0
    z = 10000000000000000
    x = 0
    y = 700000
    n = 0
    counter = 0

    while (flag == False):

    primeFlag = 0
    for i in range (2, y):
        if (y % i) == 0:
            primeFlag = primeFlag +1  
            if (primeFlag >0):
                break
        
    if (primeFlag == 0):
        print (str(y)+ " - Prime")
        for s in list(str(y)):
            if (s == "7"):
                counter = (counter + 1)

        if (counter == 5):
            print (str(y)+ " is the first prime number with at least 5 7's in!")
            flag = True
            exit()
        
        else:
            flag = False
            y = (y+1)
            counter = 0            

    else:
        y = (y+1)</pre>
                    <pre class="prettyprint">
    727777 is the first prime number with at least 5 7's in!</pre>

                    <p>While it had taken me all of Christmas day, cornered in the conservatory being force fed mince pies and cider, I’d finally done it. And got access to an email address containing multiple CD keys for games. But the truth of the matter was that the real gift my brother had given me was the reignition for my love of programming and problem solving.</p> 
                    
                    <p>In September 2019, my wife reduced her hours at work and took on the LPC (Legal Practice Course) full time. Alongside her, while still working full time, I decided to start from the ground up and enrolled in Harvard’s CS50 – Introduction to Computer Science. On Christmas Eve, 2019, I submitted my final project for CS50 – <a href="https://github.com/BAK2K3/CSRPG" target="_blank">CS50RPG</a>, and subsequently received my verified EdX certificate.</p>

                    
                    <p><img src="{{ url_for('static', filename='cs50.jpg')}}"  class="img-fluid text-center mx-auto d-block"></p>
                     
                    
                    <p>Having explored python in much more depth in CS50, I knew this was my language of choice going forward. So, in January 2020, I started a course on Udemy for Python, Data Science, and Machine Learning. The course included topics on statistics that were far beyond the scope of my mathematical capabilities, so between January and March, the majority of the time that I spent studying for this course was reading <a href="http://faculty.marshall.usc.edu/gareth-james/ISL/" target="_blank"> An Introduction to Statistical Learning </a>.</p> 
                    
                    <p>Then lockdown hit. In April 2020, the contract I was on was suspended, and I was furloughed indefinitely. This was the best time for me to completely focus on furthering my knowledge, completing as many courses as I could, and building a portfolio to demonstrate my capabilities. My wife was still completing her LPC, so together we spent over 3 months studying 7 days a week.  Shortly into the lockdown, I completed the Data Science and Machine Learning course.</p> 

                    
                    <p><img src="{{ url_for('static', filename='datascience.jpg')}}"  class="img-fluid text-center mx-auto d-block"></p>
                    
                    <p>One of the final chapters in this course covered Neural Networks with TensorFlow, and I found myself enthralled with the topic, and spent a lot of time experimenting with the small areas covered during the course and externally researching wider concepts. Given my interest in Neural Networks, I decided to enrol in a course specifically for Deep Neural Networks with TensorFlow.</p> 
                    
                    <p>Within a month I’d completed the course, and one of the final aspects was deploying a simple Neural Network via Flask. I remember thinking – <em>"This would be a great way of showcasing what I’ve learnt."</em> But with such a shallow knowledge of web design and full stack development, I thought it would be beneficial to take an additional course on Flask, and web design, to really make the most out of the experience and to present the best possible user experience as part of my portfolio.</p> 

                    
                    <p><img src="{{ url_for('static', filename='tensorflow.jpg')}}"  class="img-fluid text-center mx-auto d-block"></p>
                        
                    <p>The final course, which I completed at the beginning of June 2020, was exactly that. A Python and Flask bootcamp for web development. Armed with what I thought was a sufficient arsenal to deploy my first project to the web, a stateful Recurrent Neural Network for Natural Language Processing, I started work on the portfolio, thinking <em>"This won't be too difficult, surely?”</em></p>
                   
                 
                    <p><img src="{{ url_for('static', filename='flask.jpg')}}"  class="img-fluid text-center mx-auto d-block"></p>
                    
                </div>
            </div>
        </div>
    
    <!-- Entry Two -->

    <div class="card">
      <div class="card-header" id="headingTwo">
        <h2 class="mb-0">
          <button class="btn btn-dark btn-block text-center collapsed" type="button" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
            Dev Diary #2 - Deploying a Stateful Neural Network
          </button>
        </h2>
      </div>
      <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordianDev">
        <div class="card-body">

          <p><strong>01/07/2020</strong></p>

          <p><em>TL;DR – Deploying a stateful Neural Network was indeed, extremely difficult.</em>T</p> 

          <p>When initially planning my portfolio, I had huge prospects for what I wanted to demonstrate; most importantly, I’d hoped all my Neural Networks would be interactive in order for users to understand their application. The scope of my portfolio included Recurrent Neural Networks, Generative Adversarial Networks, and Convolutional Neural Networks. All of which, I wanted to be interactive. </p>
          
          <p>The first fully developed Network I’d created through the TensorFlow course which was accessible, relatable, and interactive, was a <a href='https://www.tensorflow.org/tutorials/text/text_generation' target="_blank">“Shakespeare Bot”</a>. Given the simple and available nature of this model, I attempted a much “deeper” network using Tolstoy’s War and Peace, and named is “Tolstoybot”. Both of these were ready prior to starting the development of the website, and so deploying these models seemed the best place to start. </p>
          
          <p>The website started off simple, with a welcome page, and a separate page for the bots. I tested them out locally on Flask, and they seemed to work out of the box. The model was hosted locally on my computer, as part of the website, and the function for obtaining predicted text worked as intended:</p>
          
          <pre class="prettyprint">         
  #Test function for generating consecutive text
  def generate_text(model,start_seed,num_generate=500,temperature=1):
      
      #Map each character in start_seed to it's relative index
      input_eval = [char_to_ind[s] for s in start_seed]
      
      #Expand the dimensions
      input_eval = tf.expand_dims(input_eval, 0)
      
      #Create empty list for generated text
      text_generated = []
      
      #Reset the states of the model        
      model.reset_states()
      
      #for each iteration of num_generate
      for i in range(num_generate):
          
          #Obtain probability matrix for current iteration 
          predictions = model(input_eval)
          
          #Reduce dimensions
          predictions = tf.squeeze(predictions,0)
          
          #Multiply probability matrix by temperature
          predictions = predictions/temperature
          
          #Select a random outcome, based on the unnormalised log-probabilities produced by the model
          predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
          
          #Expand dimensions of prediction and assign as next input evaluation
          input_eval = tf.expand_dims([predicted_id], 0)
          
          #Convert prediction to char and append to generated list of text
          text_generated.append(ind_to_char[predicted_id])
          
      #return the initial input, concatenated with the generated text. 
      return(start_seed+"".join(text_generated))</pre>
          
          <p>Feeling like I was ready to conquer the world, I set up an account on Heroku, made a new application, and pushed my git to the Heroku master channel.</p> 
          
          <pre class="prettyprint">
  Compiled slug size: 750M is too large (max is 500M)</pre>

          <p><strong>Oh.</strong> So it turns out that TensorFlow is too big for Heroku. Given showcasing my capabilities with TensorFlow was one of the most important intentions of the portfolio, I’d immediately hit a brick wall. I needed to research workarounds to the size of TensorFlow, and how to deploy these via Flask and Heroku. <a href='https://www.tensorflow.org/lite' target="_blank">TFLite</a> was one of the first solutions I’d found for a more portable version of TensorFlow, but this is primarily designed for mobile applications by the looks of things, so was outside of the scope of what I was currently capable of doing. After a little while I stumbled upon a conference talk by a Google employee, about <a href='https://www.youtube.com/watch?v=4mqFDwIdKh0' target="_blank">TensorFlow Serving</a>. The initial discussion of <em>containers</em> and <em>docker</em> was a little overwhelming, but the pure concept of it was amazing. Essentially, you deploy the model to a container, and use REST API to communicate with the container (i.e send input, receive output). This solution would potentially allow me to completely remove TensorFlow from my python environment, and would therefore substantially reduce the slug size permitted by Heroku. Let’s give it a whirl.</p> 
          
          <p>I took a little tutorial on Docker, enabled virtualisation on my Windows based computer, installed Windows Subsystem for Linux, finished the <em>“getting started”</em> Docker exercise and I was ready to go.   After a couple of runs of trial and error, I’d managed to locally host two models in the same container.</p>
          
          <pre class="prettyprint">
  model_config_list {
      config {
          name: "shakesbot",
          base_path: "/models/shakesbot",
          model_platform: "tensorflow"
      }
      config {
          name: "tolstoybot",
          base_path: "/models/tolstoybot",
          model_platform: "tensorflow"
      }
  }</pre>

          <pre class="prettyprint">
  docker run -p 8501:8501 -p 8500:8500`
  --mount type=bind,source='{PATH}\Saved_Models\Shakesbot',target=/models/shakesbot/1 
  --mount type=bind,source='{PATH}\Saved_Models\Tolstoybot',target=/models/tolstoybot/1 
  --mount type=bind,source='{PATH}\model_config.config',target=/models/model_config.config 
  -t tensorflow/serving 
  --model_config_file=/models/model_config.config</pre>
          
          <p>With the model now hosted on a container, albeit locally, I needed to rewrite my function to work with RESTful communication between the website and the container.</p>
          
          <pre class="prettyprint">
  #Create REST Function for Docker Container
  def generate_text_JSON(start_seed,num_generate=500,temperature=1):
        
      #Map each character in start_seed to it's relative index
      input_eval = [char_to_ind[s] for s in start_seed]
      
      #Expand the dimensions
      input_eval = tf.expand_dims(input_eval, 0)
        
      #Create empty list for generated text
      text_generated = []
      
      #Define headers for RESTful communication
      headers = {"content-type": "application/json"}
      
      #Commented out, as the model is no longer being passed as a parameter  
      #model.reset_states()
      
      for i in range(num_generate):
          
          #Package the current iteration into an iterable json data dump
          data = json.dumps({"signature_name": "serving_default", "instances": input_eval.numpy().tolist()})
          
          #Obtain response from container through RESTful communication 
          json_response = requests.post('http://localhost:8501/v1/models/shakesbot:predict',data=data, headers=headers)
          
          #Extract probability matrix for current iteration from Json response
          predictions = json.loads(json_response.text)
                  
          #Reduce dimensions
          predictions = tf.squeeze(predictions['predictions'],0)
          
          #Multiply probabily matrix by temperature
          predictions = predictions/temperature
          
          #Select a random outcome, based on the unnormalised log-probabilities produced by the model
          predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()
          
          #Expand dimensions of prediction and assign as next input evaluation
          input_eval = tf.expand_dims([predicted_id], 0)
          
          #Convert prediction to char and append to generated list of text
          text_generated.append(ind_to_char[predicted_id])
          
      #return the initial input, concatenated with the generated text. 
      return(start_seed+"".join(text_generated))</pre>

          <p>This took a great deal of work: learning about REST APIs, RESTful communication, JSON formatted data, deciphering and fully understanding the context of the initial function, and plenty of assistance from the trusty StackOverflow. But I’d overcome this hurdle. I was now locally hosting two aspects of the portfolio separately.</p>
          
          <p>Looking back at the function I’d created to generate text, though, I realised that there were a handful of functions which were inherited from TensorFlow. Given the nature of the transition from TensorFlow to TensorFlow Serving, I needed to try and remove all reference to TensorFlow within this function in order to push an environment to Heroku without TensorFlow being part of it. These were the functions that needed changing:</p>
          
          <pre class="prettyprint">
  #Dimension Expansion
  tf.expand_dims

  #Dimension Reduction 
  tf.squeeze

  #Randomly selecting an outcome based on unnormalized log-probabilities 
  tf.random.categorical</pre>
          
          <p>The first two were straightforward with near identical NumPy functions:</p>
          
          <pre class="prettyprint">
  #Dimension Expansion
  np.expand_dims

  #Dimension Reduction 
  np.squeeze</pre>
          
          
          <p>The next function, for random selection based on unnormalized log-probabilities, resulting in me going back the drawing board of understanding some fundamentals of statistics and probabilities. In an ideal world, NumPy would have an inbuilt function similar to Dimension Expansion and Reduction, but unfortunately the implementation of such a feature wasn’t considered a priority due to it’s <a href='https://github.com/numpy/numpy/issues/15201?fbclid=IwAR04s9NppTpPZjYNnX2_nPJuGSxUgrGT5tPZ8GAL7bNUoMBdI5H_OnOOGxc' target="_blank">niche nature</a>. The closest function I could find was:</p>
          
          <pre class="prettyprint">
  np.random.choice</pre>

          <p>However, the probability distributions had to be normalised, and have a sum of 1. With some mathematical assistance of my aforementioned brother, I was able to perform such a transformation on the probability matrix using the following simple function:</p>
          
          <pre class="prettyprint">
  #Function for calculating the exponential of the array, and normalising probability distribution
  def exp_normalize(x):
      y = np.exp(x)
      return y / y.sum()</pre>

          <p>Then, when making the random selection within the function, I could call the following:</p>
          
          <pre class="prettyprint">
  #Select a random outcome, based on the unnormalised log-probabilities produced by the model
  predicted_id = np.random.choice(vocab_size, p=exp_normalize(predictions))</pre>
          
          <p>And voila, I’d done it. The function for generating text from the model no longer required TensorFlow, and I was one step closer to being able to deploy the initial concept for the portfolio. I ported all of the code over to Flask, however as I was cleaning it up and removing any redundancies, I came across one of the functions I’d initially commented out when first attempting RESTful communication to the containerised model.</p>
  
          <pre class="prettyprint">
  #resetting the internal states of the model  
  #model.reset_states()</pre>

          <p><em>So close, yet so far.</em> Let’s quickly discuss Recurrent Neural Networks, and what it means for them to be stateful. The nature of RNNs is that they retain information from their previous calculations, allowing their outputs to be impacted by previous inputs. That’s how they’re recurrent. So for example if I were to input a start seed of “He”, the model will be more likely to subsequently produce male orientated language, given the probabilities going forward will be biased towards male contextualised language. On this basis, from the first function detailed above, before making any new predictions/generations of text, the models states need to be “reset”, so that it has no prior influence or retained knowledge of any previous predictions. The ability to reset a model’s states in between predictions was a fundamental necessity, and without the ability to do this, the internal states would continue to stack, and would no longer accurately represent the individual context of each prediction.</p>
          
          <p>Given TensorFlow Serving uses RESTful communication, it is extremely limited in the instructions that can be sent and received via models being served on a container. In essence, out of the box TF Serving only allows the request for a “prediction” based on an input; without any extensive knowledge TF Serving’s infrastructure, given it’s extensive <a href='https://www.tensorflow.org/tfx/serving/api_docs/cc/class/tensorflow/serving/server-core' target="_blank">API Docs</a>, there was no easy solution to this. I’d found a feature request <a href='https://github.com/tensorflow/serving/issues/724' target="_blank">from 2018</a> which had little traction, with the only real solution or suggestion being to build a custom binary for TF Serving’s ServerCore. I took to <a href='https://www.reddit.com/r/tensorflow/comments/hfhwwm/how_to_reset_rnn_model_states_of_a_model_being/' target="_blank">Reddit</a>, and I took to <a href='https://stackoverflow.com/questions/62570483/how-to-reset-rnn-model-states-of-a-model-being-served-on-docker' target="_blank">StackOverflow</a>, but to no avail.</p> 
          
          <p>I had to accept defeat. I was now treading in the deep waters of the unknown and came to the conclusion that whilst this is an extremely exciting and interesting development in terms of deploying Neural Networks for production, I wasn’t yet capable of embarking on this journey. I had to scrap the idea of using TensorFlow Serving, and I had to find an alternative solution.</p>
          
          <p>Whilst doing my initial research into overcoming the issue with the slug size for Heroku, I came across an alternative build of TensorFlow which only utilises the CPU. Given all the models I’d previously made were trained via a CUDA GPU (NVidia 1080Ti), I was hesitant to try and deploy a model which only utilises a CPU, given the training times themselves went from 60 seconds per epoch to 15 minutes per epoch when swapping between GPU and CPU. But at this stage, I felt like I was moving in reverse, and decided that functionality was a priority over performance.</p> 
          
          <pre class="prettyprint">
  Warning: Your slug size (406 MB) exceeds our soft limit (300 MB) which may affect boot time.</pre>

          <p>While the prospect of a slow performing Neural Network was diminishing my excitement for the finished product, the above warning when deploying the environment to Heroku with TensorFlow-CPU was music to my ears. The models were finally functional, and were deployed online. The Shakesbot had an approximate return time of 6 seconds, and the Tolstoybot had an approximate return time of 15 seconds. Ultimately, while this is significantly slower than when running locally on a GPU based environment (1 second and 3 seconds respectively), the realisation dawned on me that the functionality was absolutely a priority, and that improvements could no doubt be made down the line to improve the performance if need be. </p>
          

        </div>
      </div>
    </div>

<!-- Entry Three -->

    <div class="card">   
      <div class="card-header" id="headingThree">
        <h2 class="mb-0">
          <button class="btn btn-dark btn-block text-center collapsed" type="button" data-toggle="collapse" data-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
            Dev Diary #3 - COVIDXNet
          </button>
        </h2>
      </div>
  
      <div id="collapseThree" class="collapse" aria-labelledby="headingThree" data-parent="#accordianDev">
        <div class="card-body">
         
          <p><strong>03/07/2020</strong></p>

          <p>Whenever I talk to friends and family about Neural Networks, after their eyes have stopped glossing over, their first question is usually <em>“…but who needs a bot that can write Shakespeare?”</em>  And that’s a good question. While I personally find the concept of Neural Networks fascinating and particularly ground breaking, given this black box can learn trends from data and essentially reproduce <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" target="_blank"> any function</a>, I sometimes find it hard to explain what I can personally do  with my capabilities to  help better the world, of make someone’s life or job easier. </p>
          
          <p>Having had experience now with Autoencoders, Generative Adversarial Networks, and Convolutional Neural Networks, I took to <a href="https://www.kaggle.com/" target= "_blank"> Kaggle </a> to find some inspiration for what I could tackle next for the portfolio. I’d been interested in attempting my own form or <a href= "https://neuralstyle.art/" target= "_blank"> art transformation</a>, and while this is something I still want to experiment with, I’m now a little more aware of what my limitations are using Flask and Heroku, so decided to try and aim for something a little more realistic for the time being. I didn’t expect to deploy another interactive model; I was hoping to create a useful model, showcase its functionality, and share the repo for it.</p>
          
          <p>I did a little searching, and came across an <a href="https://www.kaggle.com/nabeelsajid917/covid-19-x-ray-10000-images/data" target= "_blank"> open source dataset of chest X Rays</a>. This dataset contains COVID 19 chest X Rays, and normal chest X Rays, and claims you can create a Machine Learning algorithm with a <em>“high accuracy”</em>.  To be honest, the only dataset I’d previously done image recognition on was the <a href = "https://en.wikipedia.org/wiki/MNIST_database" target= "_blank">MNIST dataset</a>, so while I thought I might have been aiming a little high, I thought I’d give this a go. Was a capable of training a Convolution Neural Network to detect COVID 19 from X Rays?</p> 
          
          <p>I took a quick look at the generate_images.py file from the Kaggle Dataset. This takes a generous sample of the available X Rays, and creates over a 6 thousand variations of these samples through rotation, reshaping, and transformation. This is the difference between the two types of X-Rays:</p>
          
          <p><img src="{{ url_for('static', filename='XRaySamples.jpg')}}"  class="img-fluid text-center mx-auto d-block"></p>
          
          <p>As you can see, without a medical degree, there’s no chance a lay-person can take a look at these two images and categorise them in a matter of seconds. But that’s what I was hoping to accomplished through training a Convolutional Neural Network on these images.</p>
          
          <p>The dataset from Kaggle also provided a python file to train the model, but I decided to go in blind to see what I could achieve. The generate_images.py produced two folders of images: covid and normal. The first thing I wanted to do was the split the data between training data and test data. While sklearn has an <a href= "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" target="_blank"> incredibly helpful function</a> for splitting data for training and testing purposes, given how I intended on classifying the data before and after training, I wanted to split the data itself on file prior to loading it. </p>
          
  <pre class="prettyprint">
  import sys, random, os
  import shutil
  from imutils import paths
  
  #obtain the file directory using pwd
  my_data_dir = pwd
  
  #set file path for Covid images and normal images
  all_covid  = my_data_dir + '\\all_data\\covid'
  all_normal = my_data_dir + '\\all_data\\normal'
  
  #set file path for new test and train covid data
  pathCovidTest = my_data_dir + '\\test\\covid'
  pathCovidTrain = my_data_dir + '\\train\\covid'
  
  #set file path for new test and train normal data
  pathNormalTest = my_data_dir + '\\test\\normal'
  pathNormalTrain = my_data_dir + '\\train\\normal'
  
  #function for shuffling and randomly splitting files into selected directories, with given ratio 
  def splitdirs(files, dir1, dir2, ratio):
      shuffled = files[:]
      random.shuffle(shuffled)
      num = round(len(shuffled) * ratio)
      to_dir1, to_dir2 = shuffled[:num], shuffled[num:]
      for d in dir1, dir2:
          if not os.path.exists(d):
              os.mkdir(d)
      for file in to_dir1:
          shutil.copyfile(file, os.path.join(dir1, os.path.basename(file)))
      for file in to_dir2:
          shutil.copyfile(file, os.path.join(dir2, os.path.basename(file)))
  
  #set ratio for splitting
  ratio = 0.25
  ratio = float(ratio)
        
  #call functions for splitting data
  splitdirs(imagePathsCovid, pathCovidTest, pathCovidTrain, ratio)
  splitdirs(imagePathsNormal, pathNormalTest, pathNormalTrain, ratio)</pre>
          
          
          <p>While I’m aware there probably exists a <em>much more efficient way of doing this</em>, it worked as intended, and I now had a proportional 25% train test split between COVID images and normal images. I then implemented my own image generator, so as to further obscure the data as much as possible, creating as much variation between the samples as possible.</p>
          
          <pre class="prettyprint">
  image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees
                                  width_shift_range=0.10, # Shift the pic width by a max of 5%
                                  height_shift_range=0.10, # Shift the pic height by a max of 5%
                                  rescale=1/255, # Rescale the image by normalzing it.
                                  shear_range=0.1, # Shear means cutting away part of the image (max 10%)
                                  zoom_range=0.1, # Zoom in by 10% max
                                  horizontal_flip=True, # Allo horizontal flipping
                                  fill_mode='nearest' # Fill in missing pixels with the nearest filled value
                                ) </pre>
          
          <p>The image sizes ranged from around 256 x 256 to 1024 x 1024, so met in the middle by setting the image size to 512 x 512. I then went on to create the respective training image generator and test image generator to be fed into the model. </p>
          
          <pre class="prettyprint">
  train_image_gen = image_gen.flow_from_directory(train_path,
                                                  target_size=image_shape[:2],
                                                  color_mode='rgb',
                                                  batch_size=batch_size,
                                                  class_mode='binary')</pre>

          <pre class="prettyprint">
  test_image_gen = image_gen.flow_from_directory(test_path,
                                                  target_size=image_shape[:2],
                                                  color_mode='rgb',
                                                  batch_size=batch_size,
                                                  class_mode='binary',shuffle=False)</pre>
          
          <p>The next step was to create the model. I implemented a deep CNN, with the filters doubling on each subsequent convolutional layer, and a final dense layer prior to the activation/classification layer.</p>
          
          <pre class="prettyprint">
  model = Sequential()
  
  model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
  model.add(MaxPooling2D(pool_size=(4, 4)))
  
  model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
  model.add(MaxPooling2D(pool_size=(4, 4)))
  
  model.add(Conv2D(filters=128, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
  model.add(MaxPooling2D(pool_size=(4, 4)))
  
  model.add(Flatten())
  
  model.add(Dense(128))
  model.add(Activation('relu'))
  
  model.add(Dropout(0.5))
  
  model.add(Dense(1))
  model.add(Activation('sigmoid'))
  
  model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])</pre>
          
          <p>I implemented early stopped so as to prevent over-fitting, and after only 7 epochs, the model was trained, and the accuracy and validation loss took me by surprise. I ran the test image generator through the model to obtain sample predictions, and the model was reporting a 99.2% accuracy. </p>
          
          <p><img src="{{ url_for('static', filename='model_history.png')}}"  class="img-fluid text-center mx-auto d-block"></p>
          
          <p><img src="{{ url_for('static', filename='Classification_Report.jpg')}}"  class="img-fluid mx-auto d-block"></p>
          
          <p>Now I understand that the dataset was limited given the nature of what we’re trying to detect, and while the image generators were implemented to expand upon these images to create as many variations of these samples as possible, the scope of data required to truly and more accurately detect COVID symptoms from <em>any</em> X ray image would be vast. But none-the-less, the model functioned as intended, and appeared to correctly classify COVID symptoms from chest X Ray images.</p>
          
          <p>The unexpected success of this model inspired me to attempt to deploy the model fully to the website, allowing users to upload X Ray images from the <a href=https://www.researchgate.net/post/updated_list_Last_updated_June_25th_2020_of_Coronavirus_Covid-19_dataset_and_other_Research_Resources target="_blank"> many available open source repositories</a>, to classify images on the fly. While the prior process of deploying the stateful RNN was rather overwhelming, I was confident that this was a relatively simple implementation. </p>
          
          <p>After a little bit of a hiccup with file handling, by the end of the day I’d created a routing and page for the newly named COVIDXNet, allowing users to upload an image, which gets transferred to the server, handled and transformed appropriately before being passed to the model, with a prediction being communicated back to the user. To avoid clutter on the server, the file is handled and utilised by the model before being immediately deleted, with a prediction being passed back to the webpage via a separate variable. The model is responsive, reliable and is <em>apparently</em> extremely accurate. </p>
          
          <p>For further details on the model training process, please visit the Github repo.</p>
          



                </div>
            </div>
        </div>









  </div>
  </div>

<!-- Script for code formatting -->

<script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>


{% endblock content %}